### Derivation of Formulae for False Positive Probability and Optimal Hash Functions in Bloom Filters

---

### **1. Derivation of False Positive Probability (FPP)**

#### **Concepts Behind Bloom Filters**
- A Bloom filter is a bit array of size \( m \) where \( k \) independent hash functions map elements to \( k \) bit positions.
- When an element is added, \( k \) bits corresponding to the hash values are set to 1.
- To check membership, the same \( k \) hash functions are applied. If all \( k \) bits are 1, the element is considered present.

#### **False Positive Scenario**
- A false positive occurs when a query for an element not in the set results in all \( k \) hash positions being 1, even though the element was never added.

---

#### **Step 1: Probability That a Single Bit Remains 0 After \( n \) Insertions**

Each hash function sets a bit at a random position. For a single hash function and one element:
```math
P_\text{bit\_not\_set\_1} = 1 - \frac{1}{m}
```

For \( k \) hash functions applied to one element:
```math
P_\text{bit\_not\_set\_k} = \left(1 - \frac{1}{m}\right)^k
```

For \( n \) elements:
```math
P_\text{bit\_not\_set\_kn} = \left(1 - \frac{1}{m}\right)^{kn}
```

The probability that a bit is set at least once after \( n \) elements:
```math
P_\text{bit\_set} = 1 - P_\text{bit\_not\_set\_kn} = 1 - \left(1 - \frac{1}{m}\right)^{kn}
```

---

#### **Step 2: False Positive Probability (FPP) for \( k \) Bits**

For a query of an element not in the set, the \( k \) hash functions check \( k \) bits. All \( k \) bits must independently be 1 for a false positive. The probability is:
```math
\text{FPP} = P_\text{bit\_set}^k = \left(1 - \left(1 - \frac{1}{m}\right)^{kn}\right)^k
```

This is the general formula for FPP.

---

#### **Approximation for Large \( m \) and \( kn \)**
When $$\( m \) is large, \( \left(1 - \frac{1}{m}\right) \approx e^{-1/m} \)$$, and:
```math
\left(1 - \frac{1}{m}\right)^{kn} \approx e^{-kn/m}
```

Substituting:
```math
P_\text{bit\_set} \approx 1 - e^{-kn/m}
```

So:
```math
\text{FPP} \approx \left(1 - e^{-kn/m}\right)^k
```

---

### **2. Derivation of Optimal Number of Hash Functions (\( k \))**

#### **Objective**:
Minimize FPP for a fixed \( m \) (bit array size) and \( n \) (number of elements).

#### **FPP Formula**:
Using the approximation:
```math
\text{FPP} = \left(1 - e^{-kn/m}\right)^k
```

For large \( m \), the optimal \( k \) is derived by minimizing the exponent \( e^{-kn/m} \) while balancing the probability of all \( k \) bits being set.

#### **Step 1: Taking the Derivative of FPP with Respect to \( k \)**
Using the raw formula for FPP:
```math
f(k) = \left(1 - e^{-kn/m}\right)^k
```

Take the derivative to find the value of \( k \) that minimizes \( f(k) \). After simplifications, the optimal \( k \) is found to be:
```math
k = \frac{m}{n} \ln 2
```

---

#### **Step 2: Interpretation of $$\( k = \frac{m}{n} \ln 2 \)$$**
- $$\( \frac{m}{n} \)$$: The ratio of the number of bits in the Bloom filter to the number of elements.
- $$\( \ln 2 \)$$: A constant factor derived from minimizing FPP mathematically.

This formula ensures the FPP is minimized for a given Bloom filter configuration.

---

### **Intuition Behind These Formulae**

1. **FPP Formula**:
   - The probability of a bit being set increases as more elements are added or as \( k \) increases.
   - Too many hash functions (\( k \)) lead to excessive bit overlaps, increasing FPP after a certain point.

2. **Optimal \( k \)**:
   - Increasing \( k \) initially reduces FPP by setting more bits.
   - Beyond the optimal \( k \), additional hash functions cause more collisions, increasing FPP.

---

### **Examples for Derivations**

#### Example 1: FPP Approximation
Given \( m = 1000 \), \( n = 100 \), and \( k = 5 \), calculate the approximate FPP:

1. Compute \( kn/m \):
   ```math
   kn/m = \frac{5 \cdot 100}{1000} = 0.5
   ```

2. Compute \( e^{-kn/m} \):
   ```math
   e^{-0.5} \approx 0.606
   ```

3. Probability of a bit being set:
   ```math
   P_\text{bit\_set} = 1 - 0.606 = 0.394
   ```

4. FPP:
   ```math
   \text{FPP} = (0.394)^5 \approx 0.015
   ```

---

#### Example 2: Optimal \( k \)
Given \( m = 2000 \), \( n = 100 \), calculate \( k \):

1. Compute \( m/n \):
   ```math
   m/n = 2000/100 = 20
   ```

2. Optimal \( k \):
   ```math
   k = 20 \ln 2 \approx 20 \cdot 0.693 = 13.86
   ```

Round to the nearest integer:
```math
k = 14
```

---

### **Summary**
- **FPP** is derived by analyzing the probability of overlapping bits set by multiple hash functions.
- **Optimal \( k \)** is derived by minimizing FPP for a given \( m \) and \( n \), balancing the trade-off between setting enough bits and avoiding excessive collisions.
