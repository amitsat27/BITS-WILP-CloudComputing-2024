### Kafka Topics: The Core Unit of Organization in Kafka

In Kafka, a **topic** is a category or stream of data that acts as a container for messages. Producers send messages to topics, and consumers read messages from topics. Topics are the backbone of Kafka's messaging system and are essential for organizing data flows.

---

### 1. **Characteristics of Kafka Topics**

#### a. **Partitioning**
- Each topic is divided into **partitions** for scalability and parallelism.
- Partitions are immutable logs where messages are stored sequentially.
- Messages in partitions are identified by a unique **offset**.

#### b. **Replication**
- Each partition can have multiple replicas for fault tolerance.
- One replica is the **leader**, and others are **followers**.
- The leader handles all read/write requests, and followers sync data.

#### c. **Retention**
- Kafka stores messages for a configurable period (e.g., 7 days) or until a size limit is reached.
- After the retention period, messages are deleted, freeing up storage.

#### d. **Immutable Data**
- Once written, messages in a topic cannot be modified or deleted (before the retention period ends).

---

### 2. **Key Configurations for Topics**
Topics can be customized using the following configurations:

| **Property**           | **Description**                                             |
|-------------------------|-------------------------------------------------------------|
| `num.partitions`        | Number of partitions for the topic.                         |
| `replication.factor`    | Number of replicas for each partition.                      |
| `retention.ms`          | Time to retain messages (e.g., 7 days = 604800000 ms).      |
| `retention.bytes`       | Maximum storage size for the topic before deletion occurs.  |
| `cleanup.policy`        | Message deletion policy (`delete` or `compact`).            |
| `min.insync.replicas`   | Minimum replicas that must acknowledge a write.             |

---

### 3. **How Topics Work**

#### a. **Producer to Topic Workflow**
1. **Producer** sends messages to a specific topic.
2. Messages are written to one of the topic's partitions.
3. Partition selection:
   - Based on a **key** (e.g., customer ID).
   - Default: round-robin if no key is provided.

#### b. **Consumer from Topic Workflow**
1. **Consumer** subscribes to a topic.
2. Kafka assigns specific partitions to the consumer.
3. Consumers read messages in order within a partition.

#### Example:
If `topic-A` has 3 partitions (`P0`, `P1`, `P2`):
- **Producer** sends 3 messages: `M1`, `M2`, `M3`.
- `M1` goes to `P0`, `M2` to `P1`, and `M3` to `P2`.

#### c. **Offset Management**
- Kafka assigns a unique **offset** to each message within a partition.
- Consumers track offsets to resume reading messages.

---

### 4. **Topic Replication**

- Replication ensures **high availability**.
- Example:
  - `topic-B` has 2 partitions (`P0`, `P1`) with a replication factor of 2.
  - If Broker 1 fails, Broker 2 takes over as the leader for `P0` or `P1`.

---

### 5. **Topic Cleanup Policies**

#### a. **Delete Policy**
- Default behavior.
- Deletes messages older than the retention period or when storage exceeds the configured size.

#### b. **Compact Policy**
- Keeps the latest record for each unique key.
- Useful for maintaining a **state store**.

---

### 6. **Common Commands for Kafka Topics**

#### a. **Create a Topic**
```bash
kafka-topics.sh --create --bootstrap-server localhost:9092 \
    --replication-factor 3 --partitions 3 --topic my-topic
```

#### b. **List Topics**
```bash
kafka-topics.sh --list --bootstrap-server localhost:9092
```

#### c. **Describe a Topic**
```bash
kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic my-topic
```

#### d. **Delete a Topic**
```bash
kafka-topics.sh --delete --bootstrap-server localhost:9092 --topic my-topic
```

---

### 7. **Use Cases for Topics**

- **Order Processing:** Topics for each order status (e.g., `order-created`, `order-processed`).
- **Log Aggregation:** Centralize logs from different applications.
- **Real-Time Analytics:** Stream sensor data for monitoring.
- **Event Sourcing:** Record changes to application state.
