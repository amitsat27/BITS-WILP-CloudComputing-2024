### **Aggregation of Streaming Data**

Aggregation is a key operation in streaming data pipelines to compute metrics or summaries (e.g., counts, averages, sums) over real-time data. Apache Spark Structured Streaming provides robust tools for **real-time aggregation** with low latency and fault tolerance.

---

### **Types of Streaming Aggregations**

1. **Simple Aggregations**
   - Compute basic statistics such as **count**, **sum**, **average**, etc., over unbounded streams.
   - Example: Counting the number of events in the stream.

2. **Windowed Aggregations**
   - Aggregate data over a fixed or sliding time window.
   - Example: Counting the number of events that occurred in the last 5 minutes.

3. **Stateful Aggregations**
   - Maintain state across multiple batches of streaming data.
   - Example: Computing a running total or running average.

---

### **Key Components of Aggregation**

1. **Event Time vs. Processing Time**:
   - Event Time: Time when the event actually occurred.
   - Processing Time: Time when the event is processed by the engine.

2. **Watermarking**:
   - Handles late-arriving data by defining a threshold (e.g., allow data up to 10 minutes late).

3. **Output Modes**:
   - **Append**: Outputs only new rows.
   - **Update**: Updates existing rows.
   - **Complete**: Outputs the entire aggregation result on each trigger.

---

### **Examples of Streaming Aggregations**

#### **1. Simple Aggregation (Count)**

```scala
val spark = SparkSession.builder.appName("Simple Aggregation").getOrCreate()

// Read streaming data
val lines = spark.readStream
  .format("socket")
  .option("host", "localhost")
  .option("port", 9999)
  .load()

// Split lines into words and count occurrences
val wordCounts = lines.as[String]
  .flatMap(_.split(" "))
  .groupBy("value")
  .count()

val query = wordCounts.writeStream
  .outputMode("complete")
  .format("console")
  .start()

query.awaitTermination()
```

---

#### **2. Windowed Aggregation**

Aggregate data in fixed time intervals (tumbling window) or overlapping intervals (sliding window).

##### **Tumbling Window**
Non-overlapping windows, e.g., every 5 minutes.

```scala
val windowedCounts = streamDF
  .withWatermark("eventTime", "10 minutes")
  .groupBy(window($"eventTime", "5 minutes"))
  .count()

val query = windowedCounts.writeStream
  .outputMode("complete")
  .format("console")
  .start()

query.awaitTermination()
```

##### **Sliding Window**
Overlapping windows with a slide duration, e.g., every 2 minutes with a 5-minute window.

```scala
val slidingWindowCounts = streamDF
  .withWatermark("eventTime", "10 minutes")
  .groupBy(window($"eventTime", "5 minutes", "2 minutes"))
  .count()

val query = slidingWindowCounts.writeStream
  .outputMode("complete")
  .format("console")
  .start()

query.awaitTermination()
```

---

#### **3. Stateful Aggregation**

Maintain state across batches, e.g., running total.

```scala
val runningTotal = streamDF
  .groupBy("key")
  .agg(sum("value").as("runningTotal"))

val query = runningTotal.writeStream
  .outputMode("update")
  .format("console")
  .start()

query.awaitTermination()
```

---

### **Use Cases of Aggregations**

1. **Real-Time Dashboards**:
   - Example: Monitoring metrics like website hits or CPU usage.

2. **Fraud Detection**:
   - Example: Aggregating transaction amounts over time to detect anomalies.

3. **IoT Analytics**:
   - Example: Computing rolling averages of temperature readings.

4. **Social Media Analysis**:
   - Example: Counting hashtags or mentions over time.

---

### **Performance Considerations**

1. **Partitioning**:
   - Ensure keys are evenly distributed across partitions to avoid bottlenecks.

2. **Watermarking**:
   - Choose an appropriate threshold for late data to balance accuracy and resource usage.

3. **Checkpointing**:
   - Enable checkpointing to persist the state and ensure fault tolerance.

4. **Trigger Intervals**:
   - Configure the trigger interval to control batch processing frequency.
