Below is an example using **Apache Spark Structured Streaming** where we will process a stream of text data and apply the three output modes (Complete, Append, and Update) on a word count operation. We will use a **text stream** from a directory that contains files, with new text files being added over time.

### Prerequisites:
Make sure you have a **directory** with some text files (e.g., `input_text`) where new text files will be placed periodically. Spark will read the data from this directory and process it in a streaming manner.

### Setup:

1. **Create SparkSession:**
```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import explode, split

# Initialize Spark session
spark = SparkSession.builder \
    .appName("Streaming Text Example") \
    .getOrCreate()

# Set log level to avoid unnecessary logs
spark.sparkContext.setLogLevel("WARN")
```

2. **Read Stream from Input Directory:**
We'll read text files from the directory `input_text`, which will be treated as a stream of data.
```python
# Directory path for the streaming text data
input_dir = "path/to/input_text"

# Read the streaming text data
df = spark.readStream.text(input_dir)
```

Now that the streaming DataFrame is set up, let's apply the three output modes:

---

### **1. Complete Output Mode (Full Count Every Time)**

In **Complete Mode**, the entire word count for all words in the stream will be output after each batch of data is processed. The previous results are overwritten every time new data arrives.

```python
# Split the lines into words, explode into a list of words, and count occurrences
word_counts_complete = df.select(explode(split(df.value, " ")).alias("word")) \
                         .groupBy("word") \
                         .count()

# Write the results using the complete output mode
word_counts_complete.writeStream \
    .outputMode("complete") \
    .format("console") \
    .start()
```

**Explanation**:
- Every time a new batch arrives, the **complete word count** for all words will be printed, reflecting the state of all words encountered so far in the stream.
- If the stream has 100 words in total, the output will show the count for each word across all data processed up to that point.

---

### **2. Append Output Mode (New Words Only)**

In **Append Mode**, only new words added in the most recent batch will be output, and the results will **not update previously seen word counts**. This is useful when you just want to see newly encountered words.

```python
# Write the results using the append output mode
word_counts_append = df.select(explode(split(df.value, " ")).alias("word")) \
                       .groupBy("word") \
                       .count()

word_counts_append.writeStream \
    .outputMode("append") \
    .format("console") \
    .start()
```

**Explanation**:
- Only **new words** in the most recent batch will be printed.
- This mode is typically used when new data is continuously added, and you want to append the new results without redoing the entire computation.

---

### **3. Update Output Mode (Only Updated Counts)**

In **Update Mode**, only the **updated word counts** (i.e., the word counts that have changed from the previous batch) will be output. This is useful for situations where you need to see only the differences between the last two batches.

```python
# Write the results using the update output mode
word_counts_update = df.select(explode(split(df.value, " ")).alias("word")) \
                       .groupBy("word") \
                       .count()

word_counts_update.writeStream \
    .outputMode("update") \
    .format("console") \
    .start()
```

**Explanation**:
- **Only updated word counts** will be printed.
- For example, if the word "apple" count was 3 in the previous batch and has increased to 5, only the updated count for "apple" (i.e., 5) will be printed.
- If a word hasn't changed, it won’t be printed again.

---

### **Putting it all Together**

Here is the complete example where all three output modes are applied on the same streaming data. The text files in the `input_text` directory will be processed as they arrive.

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import explode, split

# Initialize Spark session
spark = SparkSession.builder \
    .appName("Streaming Text Example") \
    .getOrCreate()

# Set log level to avoid unnecessary logs
spark.sparkContext.setLogLevel("WARN")

# Directory path for the streaming text data
input_dir = "path/to/input_text"

# Read the streaming text data
df = spark.readStream.text(input_dir)

# Split the lines into words, explode into a list of words, and count occurrences
word_counts = df.select(explode(split(df.value, " ")).alias("word")) \
                .groupBy("word") \
                .count()

# 1. Complete Output Mode (full word count)
word_counts.writeStream \
    .outputMode("complete") \
    .format("console") \
    .start()

# 2. Append Output Mode (new words only)
word_counts.writeStream \
    .outputMode("append") \
    .format("console") \
    .start()

# 3. Update Output Mode (updated word counts only)
word_counts.writeStream \
    .outputMode("update") \
    .format("console") \
    .start()

# Await termination (the stream will keep running)
spark.streams.awaitAnyTermination()
```

---

### **Test Data (input_text folder)**

Let's say you add the following text files to the `input_text` directory:

1. **File 1 (batch1.txt)**:
   ```
   hello world hello
   ```

2. **File 2 (batch2.txt)**:
   ```
   spark streaming hello
   ```

3. **File 3 (batch3.txt)**:
   ```
   world spark
   ```

### **Expected Output for Each Mode**

#### Complete Mode:
After every new batch, the complete count of each word will be shown, including all previous words encountered. For example:

```
+-----+-----+
| word|count|
+-----+-----+
| hello|    3|
| world|    2|
| spark|    2|
| streaming| 1|
+-----+-----+
```

#### Append Mode:
In this mode, only new words from the latest batch will be printed:

After **batch 1**:
```
+-----+-----+
| word|count|
+-----+-----+
| hello|    2|
| world|    1|
+-----+-----+
```

After **batch 2**:
```
+-----+-----+
| word|count|
+-----+-----+
| spark|    1|
| streaming| 1|
+-----+-----+
```

After **batch 3**:
```
+-----+-----+
| word|count|
+-----+-----+
| world|    1|
+-----+-----+
```

#### Update Mode:
In this mode, only updated counts will be printed:

After **batch 1**:
```
+-----+-----+
| word|count|
+-----+-----+
| hello|    2|
| world|    1|
+-----+-----+
```

After **batch 2**:
```
+-----+-----+
| word|count|
+-----+-----+
| hello|    3|
| spark|    1|
| streaming| 1|
+-----+-----+
```

After **batch 3**:
```
+-----+-----+
| word|count|
+-----+-----+
| world|    2|
| spark|    2|
+-----+-----+
```

---

### **Conclusion**

- **Complete mode** prints the full result, recalculated each time new data is processed.
- **Append mode** only prints newly encountered records.
- **Update mode** prints the updated results for records that have changed since the last batch.

These output modes allow you to handle streaming data in different ways depending on your use case—whether you need full recalculations, just the new data, or updates to existing data.
