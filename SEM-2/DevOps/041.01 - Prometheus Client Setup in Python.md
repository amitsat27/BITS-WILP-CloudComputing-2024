To set up a Prometheus client in Python and use **Counter**, **Histogram**, and **Gauge** metrics, you can follow these steps. Prometheus provides the `prometheus_client` library for Python to instrument your applications. 

---

### **Step 1: Install Prometheus Client Library**
Run the following command to install the library:
```bash
pip install prometheus-client
```

---

### **Step 2: Create a Python Application**

Hereâ€™s a detailed example that demonstrates the use of **Counter**, **Histogram**, and **Gauge** metrics.

```python
from prometheus_client import Counter, Gauge, Histogram, start_http_server
import time
import random

# Define metrics
# Counter: Tracks the number of operations or events
REQUEST_COUNT = Counter('app_requests_total', 'Total number of requests received')

# Histogram: Tracks the distribution of durations (e.g., request latencies)
REQUEST_LATENCY = Histogram('app_request_latency_seconds', 'Latency of requests', 
                             buckets=[0.1, 0.5, 1, 2.5, 5, 10])

# Gauge: Tracks the current value of a metric (e.g., memory usage, in-progress requests)
IN_PROGRESS_REQUESTS = Gauge('app_in_progress_requests', 'Number of in-progress requests')

# Function to simulate request processing
def process_request():
    # Increment the gauge for in-progress requests
    IN_PROGRESS_REQUESTS.inc()

    # Simulate request processing time
    latency = random.uniform(0.1, 5)  # Random latency between 0.1 and 5 seconds
    time.sleep(latency)

    # Observe the latency in the histogram
    REQUEST_LATENCY.observe(latency)

    # Increment the counter for total requests
    REQUEST_COUNT.inc()

    # Decrement the gauge after processing the request
    IN_PROGRESS_REQUESTS.dec()

# Start a Prometheus metrics server on port 8000
if __name__ == "__main__":
    start_http_server(8000)  # Expose metrics at http://localhost:8000/metrics
    print("Prometheus client running on port 8000...")

    # Simulate continuous requests
    while True:
        process_request()
```

---

### **Step 3: Run the Application**
Save the script as `app.py` and run it:
```bash
python app.py
```

---

### **Step 4: Scrape Metrics**
1. Open your browser and navigate to [http://localhost:8000/metrics](http://localhost:8000/metrics).
2. You will see metrics similar to the following:
   ```
   # HELP app_requests_total Total number of requests received
   # TYPE app_requests_total counter
   app_requests_total 25.0

   # HELP app_request_latency_seconds Latency of requests
   # TYPE app_request_latency_seconds histogram
   app_request_latency_seconds_bucket{le="0.1"} 0.0
   app_request_latency_seconds_bucket{le="0.5"} 5.0
   app_request_latency_seconds_bucket{le="1.0"} 10.0
   app_request_latency_seconds_bucket{le="2.5"} 20.0
   app_request_latency_seconds_bucket{le="5.0"} 25.0
   app_request_latency_seconds_bucket{le="10.0"} 25.0
   app_request_latency_seconds_sum 37.5
   app_request_latency_seconds_count 25.0

   # HELP app_in_progress_requests Number of in-progress requests
   # TYPE app_in_progress_requests gauge
   app_in_progress_requests 0.0
   ```

---

### **Explanation of Metrics**

1. **Counter**:
   - Tracks a cumulative value, e.g., the number of requests handled.
   - **Metric Name**: `app_requests_total`
   - Example Query: `rate(app_requests_total[5m])` (requests per second over the last 5 minutes).

2. **Histogram**:
   - Tracks distributions, e.g., latency of requests.
   - Buckets group the data into intervals for aggregation.
   - **Metric Name**: `app_request_latency_seconds`
   - Example Query: `histogram_quantile(0.95, sum(rate(app_request_latency_seconds_bucket[5m])) by (le))` (95th percentile latency).

3. **Gauge**:
   - Tracks a value that can go up and down, e.g., in-progress requests.
   - **Metric Name**: `app_in_progress_requests`
   - Example Query: `app_in_progress_requests` (current in-progress requests).

---

### **Step 5: Add Prometheus to Scrape the Python Application**
Update your Prometheus `prometheus.yml` configuration file to include your Python app:
```yaml
scrape_configs:
  - job_name: 'python_app'
    static_configs:
      - targets: ['localhost:8000']
```

---

This setup demonstrates how to integrate Prometheus metrics into a Python application. You can extend this further by adding custom labels, more metrics types, and exporting data to visualization tools like Grafana.
